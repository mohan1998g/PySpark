Data Types	
	
ArrayType(elementType[, containsNull])	Array data type.
BinaryType	Binary (byte array) data type.
BooleanType	Boolean data type.
ByteType	Byte data type, i.e.
DataType	Base class for data types.
DateType	Date (datetime.date) data type.
DecimalType([precision, scale])	Decimal (decimal.Decimal) data type.
DoubleType	Double data type, representing double precision floats.
FloatType	Float data type, representing single precision floats.
IntegerType	Int data type, i.e.
LongType	Long data type, i.e.
MapType(keyType, valueType[, valueContainsNull])	Map data type.
NullType	Null type.
ShortType	Short data type, i.e.
StringType	String data type.
CharType(length)	Char data type
VarcharType(length)	Varchar data type
StructField(name, dataType[, nullable, metadata])	A field in StructType.
StructType([fields])	Struct type, consisting of a list of StructField.
TimestampType	Timestamp (datetime.datetime) data type.
TimestampNTZType	Timestamp (datetime.datetime) data type without timezone information.
DayTimeIntervalType([startField, endField])	DayTimeIntervalType (datetime.timedelta).
YearMonthIntervalType([startField, endField])	YearMonthIntervalType, represents year-month intervals of the SQL standard
	
	
Column	
	
Column.__getattr__(item)	An expression that gets an item at position ordinal out of a list, or gets an item by key out of a dict.
Column.__getitem__(k)	An expression that gets an item at position ordinal out of a list, or gets an item by key out of a dict.
Column.alias(*alias, **kwargs)	Returns this column aliased with a new name or names (in the case of expressions that return more than one column, such as explode).
Column.asc()	Returns a sort expression based on the ascending order of the column.
Column.asc_nulls_first()	Returns a sort expression based on ascending order of the column, and null values return before non-null values.
Column.asc_nulls_last()	Returns a sort expression based on ascending order of the column, and null values appear after non-null values.
Column.astype(dataType)	astype() is an alias for cast().
Column.between(lowerBound, upperBound)	True if the current column is between the lower bound and upper bound, inclusive.
Column.bitwiseAND(other)	Compute bitwise AND of this expression with another expression.
Column.bitwiseOR(other)	Compute bitwise OR of this expression with another expression.
Column.bitwiseXOR(other)	Compute bitwise XOR of this expression with another expression.
Column.cast(dataType)	Casts the column into type dataType.
Column.contains(other)	Contains the other element.
Column.desc()	Returns a sort expression based on the descending order of the column.
Column.desc_nulls_first()	Returns a sort expression based on the descending order of the column, and null values appear before non-null values.
Column.desc_nulls_last()	Returns a sort expression based on the descending order of the column, and null values appear after non-null values.
Column.dropFields(*fieldNames)	An expression that drops fields in StructType by name.
Column.endswith(other)	String ends with.
Column.eqNullSafe(other)	Equality test that is safe for null values.
Column.getField(name)	An expression that gets a field by name in a StructType.
Column.getItem(key)	An expression that gets an item at position ordinal out of a list, or gets an item by key out of a dict.
Column.ilike(other)	SQL ILIKE expression (case insensitive LIKE).
Column.isNotNull()	True if the current expression is NOT null.
Column.isNull()	True if the current expression is null.
Column.isin(*cols)	A boolean expression that is evaluated to true if the value of this expression is contained by the evaluated values of the arguments.
Column.like(other)	SQL like expression.
Column.name(*alias, **kwargs)	name() is an alias for alias().
Column.otherwise(value)	Evaluates a list of conditions and returns one of multiple possible result expressions.
Column.over(window)	Define a windowing column.
Column.rlike(other)	SQL RLIKE expression (LIKE with Regex).
Column.startswith(other)	String starts with.
Column.substr(startPos, length)	Return a Column which is a substring of the column.
Column.when(condition, value)	Evaluates a list of conditions and returns one of multiple possible result expressions.
Column.withField(fieldName, col)	An expression that adds/replaces a field in StructType by name.
	
	
Row	
	
Row.asDict([recursive])	Return as a dict
	
	
Grouping	
	
GroupedData.agg(*exprs)	Compute aggregates and returns the result as a DataFrame.
GroupedData.apply(udf)	It is an alias of pyspark.sql.GroupedData.applyInPandas(); however, it takes a pyspark.sql.functions.pandas_udf() whereas pyspark.sql.GroupedData.applyInPandas() takes a Python native function.
GroupedData.applyInPandas(func, schema)	Maps each group of the current DataFrame using a pandas udf and returns the result as a DataFrame.
GroupedData.applyInPandasWithState(func, …)	Applies the given function to each group of data, while maintaining a user-defined per-group state.
GroupedData.avg(*cols)	Computes average values for each numeric columns for each group.
GroupedData.cogroup(other)	Cogroups this group with another group so that we can run cogrouped operations.
GroupedData.count()	Counts the number of records for each group.
GroupedData.max(*cols)	Computes the max value for each numeric columns for each group.
GroupedData.mean(*cols)	Computes average values for each numeric columns for each group.
GroupedData.min(*cols)	Computes the min value for each numeric column for each group.
GroupedData.pivot(pivot_col[, values])	Pivots a column of the current DataFrame and perform the specified aggregation.
GroupedData.sum(*cols)	Computes the sum for each numeric columns for each group.
PandasCogroupedOps.applyInPandas(func, schema)	Applies a function to each cogroup using pandas and returns the result as a DataFrame.
