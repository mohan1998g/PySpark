# Define schema for the data
schema = StructType([
        StructField("city1", StringType(), True),
        StructField("city2", StringType(), True),
        StructField("city3", StringType(), True)
])

# Data in list of tuples format with None for null values
data = [
        ("Goa", None, "AP"),
        (None, "AP", None),
        (None, None, "Bglr")
]

# Create DataFrame
df = spark.createDataFrame(data, schema)

# Show the DataFrame
df.show(truncate=False)

+-----+-----+-----+
|city1|city2|city3|
+-----+-----+-----+
|Goa  |NULL |AP   |
|NULL |AP   |NULL |
|NULL |NULL |Bglr |
+-----+-----+-----+

df1 = df.withColumn("result", coalesce("city1", "city2", "city3")).drop("city1", "city2", "city3")

df1.show()

+------+
|result|
+------+
|   Goa|
|    AP|
|  Bglr|
+------+


coalesce(*cols) checks the columns in the given order and returns the first non null value

It's useful for handling misssing data when multiple columns may have null values.

It doesn't change the underlying data, but adds a new column
